\section{The reproducibility crisis}
% First two sentences copied from Ince2012
The rise of computational science has led to unprecedented opportunities in the weather and climate sciences. Ever more powerful computers enable theories to be investigated that were thought almost intractable a decade ago, while new hardware technologies allow data collection in even the most inaccessible places. In order to analyse the vast quantities of data now available to them, modern practitioners – most of whom are not computational experts – use an increasingly rich and diverse set of software tools and packages. Today's weather or climate scientist is far more likely to be found debugging code written in Python, MATLAB, IDL, NCL or R, than to be pouring over satellite images or releasing radiosondes. 
%--

This computational revolution is not unique to the weather and climate sciences, and has led to something of a reproducibility crisis in published research \citep[e.g.][]{Peng2011}. Most papers do not make the code underpinning key findings available, nor do they adequately specify the software used to execute that code, meaning it is impossible to replicate and verify most of the computational results presented in journal articles today.

A wide range of open science advocacy groups (e.g. Mozilla Science Lab, Open Science manifesto) have sprung up and/or latched onto the crisis, and in response to their campaigning there has been a mixed response from academic journals. Some in the software game has strengthened their criteria markedly, some others (e.g. nature) now vaguely mention code, and others have done nothing at all. Those same groups (and others) have also release how-to guides and new proverance tools, and a very small number of researchers have taken it upon themselves to publish reproducible results. 

If we focus on AMS in particular, the journal has no guidelines and no researchers make their code available. Most are sympathic to the idea but don't do it. This essay argues that the primary cause of the reproducibility crisis is not a lack of computational competence (although this does play a role), adequate tooling or motivation on the part of scientists, but rather a lack of appropriate examples and protocols to follow.


%As a result, computational science is facing a credibility crisis [1,2,4,5]. The enormous scale of state-of-the-art scientific computations, using tens or hundreds of thousands of processors, presents unprecedented challenges. Numerical reproducibility is a major issue, as is hardware reliability. For some applications, even rare interactions of circuitry with stray subatomic particles matter.
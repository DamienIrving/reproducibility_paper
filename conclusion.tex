\section{Conclusion}

In order to combat the reproducibility crisis in published computational research, a simple procedure for communicating computational results has been demonstrated \citep{Irving2015} and its rationale discussed. The procedure involves three key additions to traditional scientific papers: (1) a short computation section within the paper, (2) the availability of a (preferably version controlled and publicly accessible) code repository and (3) the provision of supplementary log files that capture the data processing steps taken in producing each key result. Importantly, the procedure does not substantially increase the workload of the author, reviewers or publisher. It should provide a starting point for weather and climate scientists (and perhaps computational scientists more generally) looking to publish reproducible research, and could be adopted as a minimum standard by relevant academic journals.

With respect to your big thought, I think I need to be much more explicit in the conclusion about what this paper/proposal is and what it isn't (and also much more upfront about the limitations). The key point is that I'm proposing a *minimum standard*. It has been designed from a computational best practices viewpoint and keeps the extra work required of the author as low as possible (because time to prepare code for publication is the number 1 barrier). In particular, at a bare minimum weather and climate scientists should be scripting (so they can re-run their processing), versioning those scripts and storing their processing steps in the global attributes of their netCDF files (like NCO and CDO do) (at the moment most people script, very few version and basically nobody writes their own netCDF provenance attributes). In order to make their published results reproducible, it follows that the minimum an author would need to do is simply make the global attributes of their netCDF files available along with the associated code (in their daily repo, which again keeps the extra work low) and a description of the software used to execute that code.

Of course, like in many other aspects of life, if everyone just followed the minimum standard things wouldn't be that great. Minimum standards in the construction industry ensure that buildings won't fall over or otherwise kill their inhabitants (e.g. via the use of dangerous materials like asbestos), but if everyone only built to the minimum standard towns and cities would be hugely energy inefficient. My minimum standard ensures that the work would be reproducible (which is a massive improvement on the current state of affairs), but as you point out it would be a lot of work for readers to come along and recreate a complex workflow from those log files. Authors should seek to go beyond the minimum standards in order to improve the comprehensibility of their published computational results (e.g. use RunMyCode and/or package their software so it can be installed via pip or binstar/conda) just like builders should go for a 5-star energy efficiency rating.

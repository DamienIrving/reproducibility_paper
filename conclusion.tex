\section{Conclusion}

In order to combat the reproducibility crisis in published computational research, a simple procedure for communicating computational results has been demonstrated \citep{Irving2015} and its rationale discussed. The procedure involves three key additions to traditional scientific papers: (1) a short computation section within the paper, (2) the availability of a (preferably version controlled and publicly accessible) code repository and (3) the provision of supplementary log files that capture the data processing steps taken in producing each key result. Importantly, the procedure does not substantially increase the workload of the author, reviewers or publisher. It should provide a starting point for weather and climate scientists (and perhaps computational scientists more generally) looking to publish reproducible research, and could be adopted as a minimum standard by relevant academic journals.

The standard was developed to be consistent with recommended computational best practices and reduces the burden on the author as much as possible, as this has been identified as the most important barrier to publishing code. In particular, best practice dictates that at a minimum weather and climate scientists should be writing data analysis scripts (so they can re-run their analysis) that are version controlled (for backup and ease of sharing/collaboration) and storing the details of the analysis steps in the attributes of their netCDF data files (to ensure the complete provenance of the data). In order to make their published results reproducible, it follows that the minimum an author would need to do is simply make the history attribute of their netCDF files available along with the associated code repository and a description of the software used to execute that code. In my experience as a Software Carpentry instructor I've found that most weather and climate scientists are comfortable with the idea of scripting, but very few use version control and almost none keep track of the provenance of their data. 

Of course, like in many other aspects of life, if everyone just followed the minimum standard things wouldn't be that great. Minimum standards in the construction industry ensure that buildings won't fall over or otherwise kill their inhabitants (e.g. via the use of dangerous materials like asbestos), but if everyone only built to the minimum standard towns and cities would be hugely energy inefficient. My minimum standard ensures that the work would be reproducible (which is a massive improvement on the current state of affairs), but as you point out it would be a lot of work for readers to come along and recreate a complex workflow from those log files. Authors should seek to go beyond the minimum standards in order to improve the comprehensibility of their published computational results (e.g. use RunMyCode and/or package their software so it can be installed via pip or binstar/conda) just like builders should go for a 5-star energy efficiency rating.

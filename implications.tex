\section{Implications}

In proposing a minimum standard for the communication of computational results, the implications for authors, reviewers and publishers were carefully considered. Clearly a minimum standard would improve the reproducibility of published results, but at what cost?

\subsection{Authors}

The are numerous authors who suggest that best practices such as the use of version control and the documentation of computational steps save researchers time in the long run \citep[e.g.][]{Sandve2014,Wilson2014a}, so the proposed minimum standard is not a burden on authors in that respect. Perhaps the most important consideration 

As suggested by \citet{Easterbrook2014}, making code available can only work on the understanding that it does not involve the obligation to support others in repeating the computations.

\subsection{Reviewers}

In implementing the minimum standard, it would be important to convey to reviewers that they are not expected to review the code associated with a submission. They simply have to check that it is sufficiently documented (i.e. that the code is available in an online repository and that log files have been provided for all figures and key results). Not only would it be unrealistic to have reviewers examine submitted code due to the wide variety of software tools and programming languages out there, it would also be inconsistent with the way scientific methods have always been reviewed. For instance, in the 1980s it was common for weather and climate scientists to manually identify weather systems of interest (e.g. polar lows) from satellite imagery. The reviewers of the day were not required to go through all the satellite images and check that the author had counted correctly, they simply had to check that the criteria for polar low identification was adequately documented. This is not to say that counting errors were not made on the part of authors (as with computer code today there were surely numerous errors/bugs), it is just not the job of the reviewer to root them out. Author errors are borne out when other studies show conflicting results and/or when other authors try to replicate key results, which is a process that is greatly enhanced by having a minimum standard for the communication of computational results.

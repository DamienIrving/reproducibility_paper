\section{Implications}

In proposing a minimum standard for the communication of computational results, the implications for both authors and reviewers were carefully considered. Clearly a minimum standard would improve the reproducibility of published results, but at what cost  

Reviewers don't need to actually check the code - they just have to check that it is sufficiently documented (i.e. online code repo and appendix with command history). This is similar to the way that science has always been documented and disseminated. For the old Polar Low identification papers, reviewers didn't have to go through all the satellite images and check that the author counted correctly. They simply had to check that the criteria for Polar Low identification were adequately documented. Author errors (in code or Polar Low counting) are borne out with other studies conflicting with it and then people checking (which they can do because method is adequately documented) - this is not the job of the reviewer.

As suggested by \citet{Easterbrook2014}, making code available can only work on the understanding that it does not involve the obligation to support others in repeating the computations.

This is not to say that there might not be errors in people's code. There are surely lots (http://davidsoergel.com/posts/rampant-software-errors-undermine-scientific-results). However there were also surely lots of errors in the manual techniques of the past, and it was certainly not the responsibility of the reviewer to root them all out.
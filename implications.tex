\section{Implications}

In proposing a minimum standard for the communication of computational results, the implications for authors, reviewers and publishers were carefully considered. Clearly a minimum standard would improve the reproducibility of published results, but at what cost?

\subsection{Authors}

Blah.

\subsection{Reviewers}

In implementing the minimum standard, it would be important to convey to reviewers that they are not expected to review the code associated with a give paper. They simply have to check that it is sufficiently documented (i.e. that the code is available in an online repository and that log files have been provided for all figures and key results). Not only would it be unrealistic to have reviwers examine the submitted code due to the diversity of software tools and programming languages out there), it would also This is similar to the way that science has always been documented and disseminated. For the old Polar Low identification papers, reviewers didn't have to go through all the satellite images and check that the author counted correctly. They simply had to check that the criteria for Polar Low identification were adequately documented. Author errors (in code or Polar Low counting) are borne out with other studies conflicting with it and then people checking (which they can do because method is adequately documented) - this is not the job of the reviewer.

As suggested by \citet{Easterbrook2014}, making code available can only work on the understanding that it does not involve the obligation to support others in repeating the computations.

This is not to say that there might not be errors in people's code. There are surely lots (http://davidsoergel.com/posts/rampant-software-errors-undermine-scientific-results). However there were also surely lots of errors in the manual techniques of the past, and it was certainly not the responsibility of the reviewer to root them all out.